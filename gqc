#!/usr/bin/env python3

import argparse
import gzip
import os
import re
import sqlite3
import sys
import math

############################################################################
# UTILITIES
############################################################################

def getfp(filename):
	"""Returns a file pointer for reading based on file name"""
	if   filename.endswith('.gz'):
		return gzip.open(filename, 'rt', encoding='ISO-8859-1')
	elif filename == '-':
		return sys.stdin
	else:
		return open(filename)

def readfasta(filename):
	"""Simple fasta file iterator: yields defline, seq"""
	name = None
	seqs = []
	fp = getfp(filename)
	while True:
		line = fp.readline()
		if line == '': break
		line = line.rstrip()
		if line.startswith('>'):
			if len(seqs) > 0:
				seq = ''.join(seqs)
				yield name, seq
				name = line[1:]
				seqs = []
			else:
				name = line[1:]
		else:
			seqs.append(line)
	yield name, ''.join(seqs)
	fp.close()

COMPLEMENT = str.maketrans('ACGTRYMKWSBDHV', 'TGCAYRKMWSVHDB')

def anti(seq):
	"""Returns the reverse complement of a sequence"""
	anti = seq.translate(COMPLEMENT)[::-1]
	return anti

def prob2score(p):
	"""Convert probability to nucleotide-ish log-odds score"""
	if p == 0: return -100
	return math.log2(p/0.25)

############################################################################
# MARKOV MODEL
############################################################################

class Model:

	def __init__(self):
		self.k = None
		self.probs = {}

	def create(self, seqs, beg, end, k=3):
		"""Creates a model from a sequence"""
		self.k = k
		count = {}
		for seq in seqs:
			for i in range(beg+k, len(seq) - end):
				ctx = seq[i-k:i]
				nt = seq[i]
				# initialize with pseudocounts (Laplace smoothing)
				if ctx not in count: count[ctx] = {'A':1, 'C':1, 'G':1, 'T':1}
				if nt not in count[ctx]: count[ctx][nt] = 1
				count[ctx][nt] += 1

		mm = {}
		for kmer in count:
			mm[kmer] = {}
			total = 0
			for nt in count[kmer]: total += count[kmer][nt]
			for nt in count[kmer]: mm[kmer][nt] = count[kmer][nt] / total
		self.probs = mm

	def score(self, seq):
		"""Scores the model against a sequence"""
		score = 0
		k = self.k
		mm = self.probs
		for i in range(k, len(seq)):
			kmer = seq[i-k:i]
			query = seq[i]
			ctx = mm.get(kmer)
			if ctx is None:
				p = 0.25
			else:
				p = ctx.get(query, 0.25)
			# convert to log-odds
			score += prob2score(p)
		return score

	def export_file(self, file):
		"""Exports the Markov model to a named file"""
		mm = self.probs
		with open(file, 'w') as fp:
			fp.write(f'% MM {file} {len(mm)*4}\n')
			for kmer in sorted(mm):
				for v in mm[kmer]:
					fp.write(f'{kmer}{v} {mm[kmer][v]:.6f}\n')
				fp.write('\n')

	def import_file(self, file):
		"""Imports a Markov model from a named file"""
		# expect lines of the form '<kmer><nt> <prob>' (same format as export_file)
		mm = {}
		k = None
		with open(file) as fp:
			for line in fp:
				if line.startswith('%'): continue
				f = line.split()
				if len(f) != 2: continue
				key, val = f[0], float(f[1])
				if len(key) < 2: continue
				kmer, nt = key[:-1], key[-1]
				if k is None: k = len(kmer)
				if kmer not in mm: mm[kmer] = {'A':0, 'C':0, 'G':0, 'T':0}
				mm[kmer][nt] = val
		self.k = k
		self.probs = mm

############################################################################
# CLASS DEFINITIONS
############################################################################

class Feature:
	"""represents a genomic feature"""
	def __init__(self, f):
		(sid, src, ft, beg, end, sc, st, ph, fid, pid, info) = f
		self.seqid = sid
		self.source = src
		self.type = ft
		self.beg = beg
		self.end = end
		self.score = sc
		self.strand = st
		self.phase = ph
		self.fid = fid
		self.pid = pid
		self.info = info

	def __str__(self):
		return f'{self.type} {self.beg} {self.end} {self.strand}'

class Gene:
	"""represents a gene"""
	def __init__(self, gf, txs):
		self.seqid = gf.seqid
		self.fid = gf.fid
		self.beg = gf.beg
		self.end = gf.end
		self.strand = gf.strand
		self.score = None # reserved for later
		self.transcripts = txs

	def __str__(self):
		lines = []
		lines.append(f'Gobj: {self.beg} {self.end}')
		for tx in self.transcripts:
			lines.append(f'  {tx}')
			for ex in tx.exons:
				lines.append(f'    {ex}')
		return '\n'.join(lines)

class Transcript:
	def __init__(self, txf):
		# from transcript feature
		self.seqid = txf.seqid
		self.beg = txf.beg
		self.end = txf.end
		self.strand = txf.strand
		self.score = txf.score
		self.fid = txf.fid
		self.pid = txf.pid

		# added to transcript
		self.exons = []
		self.introns = []
		self.cdss = []
		self.utr5s = []
		self.utr3s = []
		self.polya = None

		# calculated later
		self.is_coding = None
		self.is_spliced = None
		self.is_valid = None

	def __str__(self):
		return f'TXobj: {self.seqid}:{self.beg}..{self.end}{self.strand}'



############################################################################
# DATABASE FUNCTIONS
############################################################################

def create_database(db, fasta, gff3):
	"""create a new instance of database"""

	if os.path.exists(db): sys.exit(f'aborting: database {db} exists')
	con = sqlite3.connect(db)
	cur = con.cursor()

	# sequences
	cur.execute('CREATE TABLE sequence(seqid TEXT, seq TEXT, info TEXT)')
	cur.execute('CREATE INDEX idx_seq ON sequence (seqid)')
	for header, seq in readfasta(fasta):
		f = header.split()
		if len(f) == 1:
			seqid = f[0]
			info = ''
		else:
			seqid = f[0]
			info = ' '.join(f[1:])
		sql = f'INSERT INTO sequence VALUES ("{seqid}", "{seq}", "{info}")'
		cur.execute(sql)

	# features
	cur.execute('CREATE TABLE feature(seqid TEXT, source TEXT, type TEXT, beg INTEGER, end INTEGER, score NUMERIC, strand TEXT, phase TEXT, fid TEXT, pid TEXT, att TEXT)')
	cur.execute('CREATE INDEX idx_sid ON feature (seqid)')
	cur.execute('CREATE INDEX idx_fid ON feature (fid)')
	cur.execute('CREATE INDEX idx_pid ON feature (pid)')
	cur.execute('CREATE INDEX idx_typ ON feature (type)')
	cur.execute('CREATE INDEX idx_src ON feature (source)')

	grouping = 'ID', 'Parent'

	with getfp(gff3) as fp:
		for line in fp:
			if line.startswith('#'): continue
			f = line.rstrip().split('\t')
			if len(f) != 9: sys.exit('GFF3 requires 9 fields')
			sid, src, typ, beg, end, sc, st, ph, att = f
			info = {k:'' for k in grouping}
			for tv in att.rstrip(';').split(';'):
				tag, value = tv.split('=')
				info[tag] = value

			parent = [] # create duplicate features for multi-parents
			if 'Parent' in info:
				for p in info['Parent'].rstrip(',').split(','):
					parent.append(p)
			else: parent.append('')

			score = 0 if sc == '.' else sc
			fid = info['ID']

			for pid in parent:
				fields = []
				fields.append(f'"{sid}"')
				fields.append(f'"{src}"')
				fields.append(f'"{typ}"')
				fields.append(f'{beg}')
				fields.append(f'{end}')
				fields.append(f'{score}')
				fields.append(f'"{st}"')
				fields.append(f'"{ph}"')
				fields.append(f'"{fid}"')
				fields.append(f'"{pid}"')
				fields.append(f'"{att}"')
				ftxt = ','.join(fields)
				sql = f'INSERT INTO feature VALUES({ftxt})'
				cur.execute(sql)

	con.commit()

def get_seq(db, seqid, beg=None, end=None):
	"""retrieve sequence or subsequence"""

	if not os.path.exists(db): sys.exit(f'aborting: no database {db}')
	con = sqlite3.connect(db)
	cur = con.cursor()

	if beg is None and end is None:
		qseq = 'seq'
	elif end is None:
		qseq = f'substr(seq, {beg})'
	elif beg is None:
		qseq = f'substr(seq, 1, {end})'
	else:
		offset = beg
		length = end - beg + 1
		qseq = f'substr(seq, {offset}, {length})'

	query = f'SELECT {qseq} FROM sequence WHERE seqid="{seqid}"'
	seq = cur.execute(query).fetchone()[0]
	return seq

def get_features(db, seqid=None, ftype=None, source=None, fid=None, pid=None):
	"""retrieve features with filters"""

	if not os.path.exists(db): sys.exit(f'aborting: no database {db}')
	con = sqlite3.connect(db)
	cur = con.cursor()

	where = []
	if seqid:  where.append(f'seqid="{seqid}"')
	if ftype:  where.append(f'type="{ftype}"')
	if source: where.append(f'source="{source}"')
	if fid:    where.append(f'fid="{fid}"')
	if pid:    where.append(f'pid="{pid}"')
	query = 'select * from feature';
	if where: query += ' WHERE ' + ' and '.join(where)
	for f in cur.execute(query).fetchall(): yield Feature(f)

def get_seqfeats(db, seqid=None, ftype=None, source=None):
	"""retrive sequences of features with filters"""

	for f in get_features(db, seqid=seqid, ftype=ftype, source=source):
		seq = get_seq(db, f.seqid, beg=f.beg, end=f.end)
		yield seq

def get_genes(db,  seqid=None, source=None, fid=None, pid=None):
	"""retrieve all protein-coding genes"""

	if not os.path.exists(db): sys.exit(f'aborting: no database {db}')
	con = sqlite3.connect(db)
	cur = con.cursor()

	for genef in get_features(db, ftype='gene'):
		# find all transcripts where pid == fid
		txos = []
		for txf in get_features(db, pid=genef.fid):
			txo = Transcript(txf)
			for f in get_features(db, pid=txf.fid):
				if   f.type == 'exon': txo.exons.append(f)
				elif f.type == 'intron': txo.introns.append(f)
				elif f.type == 'CDS': txo.cdss.append(f)
				elif f.type == 'five_prime_UTR': txo.utr5s.append(f)
				elif f.type == 'three_prime_UTR': txo.utr3s.append(f)
				else: sys.exit(f'unknown ftype for tx: {f.type}')
			txos.append(txo)
		yield Gene(genef, txos)


############################################################################
# ACTIONS
############################################################################

def cli_create_database(arg):
	create_database(arg.db, arg.fasta, arg.gff3)

def cli_get_seq(arg):
	seq = get_seq(arg.db, arg.chrom, arg.beg, arg.end)
	print(seq)
	# change to fasta

def cli_get_features(arg):
	for f in get_features(arg.db, arg.chrom, arg.ftype, arg.source):
		print(f)
		# change to gff

def cli_get_seqfeats(arg):
	for s in get_seqfeats(arg.db, arg.chrom, arg.ftype, arg.source):
		print(s)
		# change to fasta

def cli_get_genes(arg):
	for gene in get_genes(arg.db):
		print(gene)

def cli_train_models(arg):
	if arg.verbose:
		print('Verbose mode enabled for training')
		print(f'Using DB: {arg.db}')
		print(f'Force overwrite: {bool(arg.force)}')
	
	if arg.force or not os.path.exists('baseline.mm'):
		print('Training baseline model...')
		# train baseline from full genome sequences (not feature subsequences)
		con = sqlite3.connect(arg.db)
		cur = con.cursor()
		seqids = [r[0] for r in cur.execute('SELECT seqid FROM sequence').fetchall()]
		gen_seqs = [get_seq(arg.db, sid) for sid in seqids]
		mmbase = Model()
		mmbase.create(seqs=gen_seqs, beg=0, end=0, k=arg.k)
		mmbase.export_file('baseline.mm')
		print('Baseline model trained and saved to baseline.mm')
	else:
		print('Baseline model already exists; use --f to overwrite')
	
	if (not arg.force) and os.path.exists('exon.mm') and os.path.exists('intron.mm'):
		print('Exon and intron models already exist; use --f to overwrite')
		return
		
	print('Collecting exon and intron sequences...')
	eseqs = []
	iseqs = []
	for gene in get_genes(arg.db):
		for tx in gene.transcripts:
			if arg.verbose: print(f'  processing {tx}')
			for exon in tx.exons:
				eseq = get_seq(arg.db, exon.seqid, beg=exon.beg, end=exon.end)
				# orient to + strand for model training
				if exon.strand == '-':
					eseq = anti(eseq)
				eseqs.append(eseq)
				if arg.verbose: print(f'    exon {exon.beg}-{exon.end} len={len(eseq)}')
			for intron in tx.introns:
				iseq = get_seq(arg.db, intron.seqid, beg=intron.beg, end=intron.end)
				if intron.strand == '-':
					iseq = anti(iseq)
				iseqs.append(iseq)
				if arg.verbose: print(f'    intron {intron.beg}-{intron.end} len={len(iseq)}')
	if arg.verbose:
		print(f'Collected {len(eseqs)} exon sequences and {len(iseqs)} intron sequences')
	
	print('Training exon model...')
	mmexon = Model()
	mmexon.create(eseqs,0,0,k=arg.k)
	mmexon.export_file('exon.mm')
	print('Exon model trained and saved to exon.mm')

	print('Training intron model...')
	mmintron = Model()
	mmintron.create(iseqs,0,0,k=arg.k)
	mmintron.export_file('intron.mm')
	print('Intron model trained and saved to intron.mm')

def cli_find_bad_genes(arg):
	badgenes = []

	if arg.verbose:
		print('Verbose mode enabled for scoring')
		print('Loading models: baseline.mm, exon.mm, intron.mm')
		print(f'Using DB: {arg.db}')

	mmbase = Model()
	mmbase.import_file('baseline.mm')

	mmexon = Model()
	mmexon.import_file('exon.mm')

	mmintron = Model()
	mmintron.import_file('intron.mm')

	print('Scoring transcripts...')
	total_tx = 0
	for gene in get_genes(arg.db):
		total_tx += len(gene.transcripts)
		for tx in gene.transcripts:
			if arg.verbose: print(f'  scoring {tx}')

			# accumulate raw log-odds scores and position counts to normalize later
			model_score = 0.0
			model_pos = 0
			baseline_score = 0.0
			baseline_pos = 0

			for exon in tx.exons:
				eseq = get_seq(arg.db, exon.seqid, beg=exon.beg, end=exon.end)
				if exon.strand == '-': eseq = anti(eseq)

				# exon model
				s = mmexon.score(eseq)
				p = max(0, len(eseq) - (mmexon.k or 0))
				model_score += s
				model_pos += p

				# baseline model
				sb = mmbase.score(eseq)
				pb = max(0, len(eseq) - (mmbase.k or 0))
				baseline_score += sb
				baseline_pos += pb

				if arg.verbose: print(f'    exon score {s} baseline {sb} positions {p}/{pb}')
			for intron in tx.introns:
				iseq = get_seq(arg.db, intron.seqid, beg=intron.beg, end=intron.end)
				if intron.strand == '-': iseq = anti(iseq)

				# intron model
				si = mmintron.score(iseq)
				pi = max(0, len(iseq) - (mmintron.k or 0))
				model_score += si
				model_pos += pi

				# baseline model
				si_b = mmbase.score(iseq)
				pi_b = max(0, len(iseq) - (mmbase.k or 0))
				baseline_score += si_b
				baseline_pos += pi_b

				if arg.verbose: print(f'    intron score {si} baseline {si_b} positions {pi}/{pi_b}')

			# normalize per-position (avoid division by zero)
			if model_pos == 0 or baseline_pos == 0:
				continue
			model_norm = model_score / model_pos
			baseline_norm = baseline_score / baseline_pos

			if arg.verbose: print(f'  tx norm: model {model_norm:.4f} baseline {baseline_norm:.4f}')
			
			# single metric: difference (baseline - model) per-position log-odds
			diff = baseline_norm - model_norm
			if diff > 0:
				badgenes.append((gene, tx, diff))
	
	if arg.verbose: print('\nSorting bad genes...')
	# sort by difference (largest baseline- model first)
	badgenes.sort(key=lambda tup: tup[2], reverse=True)

	if arg.verbose:
		print(f'Found {len(badgenes)} unlikely transcripts out of {total_tx} total transcripts')

	print('\nUnlikely transcripts:')
	for gene, tx, diff in badgenes:
		print(f'{gene.fid}\t{tx.fid}\t{tx}   \tdiff={diff:.4f}')

#	import isoform
#	acc = isoform.create_pwm(accs)

		

############################################################################
# CLI
############################################################################

## parent parser
parser = argparse.ArgumentParser()
parser.add_argument('--db', metavar='<file.db>', default='genome.db',
	help='genome database file [%(default)s]')
sub = parser.add_subparsers(required=True, help='sub-commands')

## create genome database
s1 = sub.add_parser('create',
	help='create a genome database from fasta and gff3 files')
s1.add_argument('--fasta', metavar='<file.fa>', required=True,
	help='genome fasta file, compressed ok')
s1.add_argument('--gff3', metavar='<file.gff3>', required=True,
	help='genome gff3 file, compressed ok')
s1.set_defaults(func=cli_create_database)

## get sequence using coordinates
s2 = sub.add_parser('getseq', help='get sequences or subsequences as FASTA')
s2.add_argument('--chrom', metavar='<name>', required=True,
	help='chromosome name [defaults to all]')
s2.add_argument('--beg', type=int, metavar='<int>', help='beg of subsequence')
s2.add_argument('--end', type=int, metavar='<int>', help='end of subsequence')
s2.add_argument('--anti', action='store_true',
	help='reverse complement the sequence after retrieval')
s2.set_defaults(func=cli_get_seq)

## get features
s3 = sub.add_parser('features', help='get features')
s3.add_argument('--chrom', help='limit to specific chromosome(s)')
s3.add_argument('--ftype', help='limit to specific type(s)')
s3.add_argument('--source', help='limit to specific source(s)')
s3.set_defaults(func=cli_get_features)

## get sequences of features
s4 = sub.add_parser('seqfeats', help='get sequences of features')
s4.add_argument('--chrom', help='limit to specific chromosome(s)')
s4.add_argument('--source', help='limit to specific source(s)')
s4.add_argument('--ftype', help='limit to specific type(s)')
s4.add_argument('--plus', action='store_true',
	help='convert sequence to + strand')
s4.set_defaults(func=cli_get_seqfeats)

## get genes and transcripts
s5 = sub.add_parser('genes', help='get genes')
s5.add_argument('--source')
s5.add_argument('--seq', action='store_true', help='report sequence')
s5.add_argument('--tx', help='send transcripts to named file')
s5.add_argument('--cds', help='send CDS to named file')
s5.set_defaults(func=cli_get_genes)

## train models
s6 = sub.add_parser('models', help='train Markov models')
s6.add_argument('-f', '--force', action='store_true',
	help='force overwrite of existing .mm files')
s6.add_argument('-v', '--verbose', action='store_true',
	help='verbose output')
s6.add_argument('-k', type=int, default=3,
	help='Markov model order [%(default)s]')
s6.set_defaults(func=cli_train_models)

## score markov
s7 = sub.add_parser('findbgs', help='get unlikely transcripts')
s7.add_argument('-v', '--verbose', action='store_true',
	help='verbose output')
s7.set_defaults(func=cli_find_bad_genes)


## execute sub-command
arg = parser.parse_args()
arg.func(arg)